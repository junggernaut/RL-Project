{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import gymnasium \n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "\n",
    "SEED = 42\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.state_values = []\n",
    "        self.is_terminals = []\n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.state_values[:]\n",
    "        del self.is_terminals[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                nn.Linear(state_dim, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, action_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                nn.Linear(state_dim, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, action_dim),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def act(self, state):\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        state_val = self.critic(state)\n",
    "\n",
    "        return action.detach(), action_logprob.detach(), state_val.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        self.buffer = RolloutBuffer()\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "            {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "        ])\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "    def update(self):\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "        old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
    "        # calculate advantages\n",
    "        advantages = rewards.detach() - old_state_values.detach()\n",
    "    \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "            # Finding Surrogate Loss   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, rewards) - 0.01 * dist_entropy\n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_name = \"CartPole-v1\"\n",
    "# has_continuous_action_space = False\n",
    "# max_ep_len = 400                    # max timesteps in one episode\n",
    "# max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
    "# print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
    "# log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "# save_model_freq = int(2e4)      # save model frequency (in num timesteps)\n",
    "# action_std = None\n",
    "\n",
    "# update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
    "# K_epochs = 40               # update policy for K epochs\n",
    "# eps_clip = 0.2              # clip parameter for PPO\n",
    "# gamma = 0.99                # discount factor\n",
    "# lr_actor = 0.0003       # learning rate for actor network\n",
    "# lr_critic = 0.001       # learning rate for critic network\n",
    "# random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "\n",
    "env_name = \"HalfCheetah-v4\"\n",
    "has_continuous_action_space = True\n",
    "max_ep_len = 1000                   # max timesteps in one episode\n",
    "max_training_timesteps = int(1e6)   # break training loop if timeteps > max_training_timesteps\n",
    "print_freq = max_ep_len * 8                # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2                  # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = int(5e4)      # save model frequency (in num timesteps)\n",
    "\n",
    "action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
    "action_std_decay_rate = 0.05        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
    "min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
    "action_std_decay_freq = int(2.5e5)  # action_std decay frequency (in num timesteps)\n",
    "\n",
    "update_timestep = max_ep_len * 3      # update policy every n timesteps\n",
    "K_epochs = 30               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "random_seed = 0         # set random seed if required (0 = no random seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training environment name : HalfCheetah-v4\n",
      "17\n",
      "6\n",
      "[-0.72350574  0.05882889 -0.68134344  0.16868737  0.3653619   0.5693678 ]\n",
      "current logging run number for HalfCheetah-v4 :  4\n",
      "logging at : PPO_logs/HalfCheetah-v4//PPO_HalfCheetah-v4_log_4.csv\n",
      "save checkpoint path : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "print(\"training environment name : \" + env_name)\n",
    "env = gym.make(env_name)\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "print(state_dim)\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    print(action_dim)\n",
    "    print(env.action_space.sample())\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "#### create new log file for each run \n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "\n",
    "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "directory = directory + '/' + env_name + '/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"save checkpoint path : \" + checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at (GMT) :  2024-06-06 02:57:07\n",
      "============================================================================================\n",
      "Episode : 7 \t\t Timestep : 8000 \t\t Average Reward : -311.52\n",
      "Episode : 15 \t\t Timestep : 16000 \t\t Average Reward : -258.22\n",
      "Episode : 23 \t\t Timestep : 24000 \t\t Average Reward : -272.22\n",
      "Episode : 31 \t\t Timestep : 32000 \t\t Average Reward : -237.6\n",
      "Episode : 39 \t\t Timestep : 40000 \t\t Average Reward : -207.23\n",
      "Episode : 47 \t\t Timestep : 48000 \t\t Average Reward : -208.6\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:33\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 55 \t\t Timestep : 56000 \t\t Average Reward : -182.9\n",
      "Episode : 63 \t\t Timestep : 64000 \t\t Average Reward : -203.83\n",
      "Episode : 71 \t\t Timestep : 72000 \t\t Average Reward : -178.63\n",
      "Episode : 79 \t\t Timestep : 80000 \t\t Average Reward : -181.58\n",
      "Episode : 87 \t\t Timestep : 88000 \t\t Average Reward : -176.65\n",
      "Episode : 95 \t\t Timestep : 96000 \t\t Average Reward : -195.74\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:03:07\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 103 \t\t Timestep : 104000 \t\t Average Reward : -168.16\n",
      "Episode : 111 \t\t Timestep : 112000 \t\t Average Reward : -134.41\n",
      "Episode : 119 \t\t Timestep : 120000 \t\t Average Reward : -108.22\n",
      "Episode : 127 \t\t Timestep : 128000 \t\t Average Reward : -125.56\n",
      "Episode : 135 \t\t Timestep : 136000 \t\t Average Reward : -148.63\n",
      "Episode : 143 \t\t Timestep : 144000 \t\t Average Reward : -114.09\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:40\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 151 \t\t Timestep : 152000 \t\t Average Reward : -77.95\n",
      "Episode : 159 \t\t Timestep : 160000 \t\t Average Reward : -62.09\n",
      "Episode : 167 \t\t Timestep : 168000 \t\t Average Reward : -79.93\n",
      "Episode : 175 \t\t Timestep : 176000 \t\t Average Reward : -30.49\n",
      "Episode : 183 \t\t Timestep : 184000 \t\t Average Reward : -50.57\n",
      "Episode : 191 \t\t Timestep : 192000 \t\t Average Reward : -70.39\n",
      "Episode : 199 \t\t Timestep : 200000 \t\t Average Reward : -15.47\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:06:15\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 207 \t\t Timestep : 208000 \t\t Average Reward : -16.83\n",
      "Episode : 215 \t\t Timestep : 216000 \t\t Average Reward : 36.48\n",
      "Episode : 223 \t\t Timestep : 224000 \t\t Average Reward : 25.0\n",
      "Episode : 231 \t\t Timestep : 232000 \t\t Average Reward : 162.82\n",
      "Episode : 239 \t\t Timestep : 240000 \t\t Average Reward : 32.79\n",
      "Episode : 247 \t\t Timestep : 248000 \t\t Average Reward : 123.27\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.55\n",
      "--------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:07:51\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 255 \t\t Timestep : 256000 \t\t Average Reward : 122.53\n",
      "Episode : 263 \t\t Timestep : 264000 \t\t Average Reward : 151.26\n",
      "Episode : 271 \t\t Timestep : 272000 \t\t Average Reward : 166.83\n",
      "Episode : 279 \t\t Timestep : 280000 \t\t Average Reward : 74.33\n",
      "Episode : 287 \t\t Timestep : 288000 \t\t Average Reward : 169.49\n",
      "Episode : 295 \t\t Timestep : 296000 \t\t Average Reward : 189.04\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:09:24\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 303 \t\t Timestep : 304000 \t\t Average Reward : 117.49\n",
      "Episode : 311 \t\t Timestep : 312000 \t\t Average Reward : 64.46\n",
      "Episode : 319 \t\t Timestep : 320000 \t\t Average Reward : 204.71\n",
      "Episode : 327 \t\t Timestep : 328000 \t\t Average Reward : 221.53\n",
      "Episode : 335 \t\t Timestep : 336000 \t\t Average Reward : 168.82\n",
      "Episode : 343 \t\t Timestep : 344000 \t\t Average Reward : 232.46\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:10:56\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 351 \t\t Timestep : 352000 \t\t Average Reward : 176.77\n",
      "Episode : 359 \t\t Timestep : 360000 \t\t Average Reward : 252.52\n",
      "Episode : 367 \t\t Timestep : 368000 \t\t Average Reward : 195.7\n",
      "Episode : 375 \t\t Timestep : 376000 \t\t Average Reward : 247.06\n",
      "Episode : 383 \t\t Timestep : 384000 \t\t Average Reward : 222.9\n",
      "Episode : 391 \t\t Timestep : 392000 \t\t Average Reward : 257.75\n",
      "Episode : 399 \t\t Timestep : 400000 \t\t Average Reward : 231.82\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:12:29\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 407 \t\t Timestep : 408000 \t\t Average Reward : 233.8\n",
      "Episode : 415 \t\t Timestep : 416000 \t\t Average Reward : 204.14\n",
      "Episode : 423 \t\t Timestep : 424000 \t\t Average Reward : 171.05\n",
      "Episode : 431 \t\t Timestep : 432000 \t\t Average Reward : 268.42\n",
      "Episode : 439 \t\t Timestep : 440000 \t\t Average Reward : 348.1\n",
      "Episode : 447 \t\t Timestep : 448000 \t\t Average Reward : 288.8\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:14:00\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 455 \t\t Timestep : 456000 \t\t Average Reward : 322.21\n",
      "Episode : 463 \t\t Timestep : 464000 \t\t Average Reward : 277.45\n",
      "Episode : 471 \t\t Timestep : 472000 \t\t Average Reward : 305.14\n",
      "Episode : 479 \t\t Timestep : 480000 \t\t Average Reward : 212.64\n",
      "Episode : 487 \t\t Timestep : 488000 \t\t Average Reward : 332.07\n",
      "Episode : 495 \t\t Timestep : 496000 \t\t Average Reward : 247.66\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.5\n",
      "--------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:15:36\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 503 \t\t Timestep : 504000 \t\t Average Reward : 337.53\n",
      "Episode : 511 \t\t Timestep : 512000 \t\t Average Reward : 358.55\n",
      "Episode : 519 \t\t Timestep : 520000 \t\t Average Reward : 393.73\n",
      "Episode : 527 \t\t Timestep : 528000 \t\t Average Reward : 376.23\n",
      "Episode : 535 \t\t Timestep : 536000 \t\t Average Reward : 369.96\n",
      "Episode : 543 \t\t Timestep : 544000 \t\t Average Reward : 451.17\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:18:10\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 551 \t\t Timestep : 552000 \t\t Average Reward : 319.64\n",
      "Episode : 559 \t\t Timestep : 560000 \t\t Average Reward : 399.99\n",
      "Episode : 567 \t\t Timestep : 568000 \t\t Average Reward : 398.3\n",
      "Episode : 575 \t\t Timestep : 576000 \t\t Average Reward : 430.68\n",
      "Episode : 583 \t\t Timestep : 584000 \t\t Average Reward : 318.32\n",
      "Episode : 591 \t\t Timestep : 592000 \t\t Average Reward : 377.12\n",
      "Episode : 599 \t\t Timestep : 600000 \t\t Average Reward : 428.29\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:19:58\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 607 \t\t Timestep : 608000 \t\t Average Reward : 449.13\n",
      "Episode : 615 \t\t Timestep : 616000 \t\t Average Reward : 415.09\n",
      "Episode : 623 \t\t Timestep : 624000 \t\t Average Reward : 408.9\n",
      "Episode : 631 \t\t Timestep : 632000 \t\t Average Reward : 501.63\n",
      "Episode : 639 \t\t Timestep : 640000 \t\t Average Reward : 450.63\n",
      "Episode : 647 \t\t Timestep : 648000 \t\t Average Reward : 458.28\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:21:39\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 655 \t\t Timestep : 656000 \t\t Average Reward : 440.42\n",
      "Episode : 663 \t\t Timestep : 664000 \t\t Average Reward : 332.24\n",
      "Episode : 671 \t\t Timestep : 672000 \t\t Average Reward : 430.92\n",
      "Episode : 679 \t\t Timestep : 680000 \t\t Average Reward : 424.39\n",
      "Episode : 687 \t\t Timestep : 688000 \t\t Average Reward : 438.69\n",
      "Episode : 695 \t\t Timestep : 696000 \t\t Average Reward : 304.46\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:23:59\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 703 \t\t Timestep : 704000 \t\t Average Reward : 453.55\n",
      "Episode : 711 \t\t Timestep : 712000 \t\t Average Reward : 455.6\n",
      "Episode : 719 \t\t Timestep : 720000 \t\t Average Reward : 383.67\n",
      "Episode : 727 \t\t Timestep : 728000 \t\t Average Reward : 451.63\n",
      "Episode : 735 \t\t Timestep : 736000 \t\t Average Reward : 438.52\n",
      "Episode : 743 \t\t Timestep : 744000 \t\t Average Reward : 465.13\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.45\n",
      "--------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:26:27\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 751 \t\t Timestep : 752000 \t\t Average Reward : 390.06\n",
      "Episode : 759 \t\t Timestep : 760000 \t\t Average Reward : 582.43\n",
      "Episode : 767 \t\t Timestep : 768000 \t\t Average Reward : 529.26\n",
      "Episode : 775 \t\t Timestep : 776000 \t\t Average Reward : 558.2\n",
      "Episode : 783 \t\t Timestep : 784000 \t\t Average Reward : 600.65\n",
      "Episode : 791 \t\t Timestep : 792000 \t\t Average Reward : 501.42\n",
      "Episode : 799 \t\t Timestep : 800000 \t\t Average Reward : 540.23\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:28:49\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 807 \t\t Timestep : 808000 \t\t Average Reward : 581.5\n",
      "Episode : 815 \t\t Timestep : 816000 \t\t Average Reward : 606.9\n",
      "Episode : 823 \t\t Timestep : 824000 \t\t Average Reward : 593.09\n",
      "Episode : 831 \t\t Timestep : 832000 \t\t Average Reward : 431.92\n",
      "Episode : 839 \t\t Timestep : 840000 \t\t Average Reward : 560.19\n",
      "Episode : 847 \t\t Timestep : 848000 \t\t Average Reward : 414.53\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:31:43\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 855 \t\t Timestep : 856000 \t\t Average Reward : 566.65\n",
      "Episode : 863 \t\t Timestep : 864000 \t\t Average Reward : 579.06\n",
      "Episode : 871 \t\t Timestep : 872000 \t\t Average Reward : 456.82\n",
      "Episode : 879 \t\t Timestep : 880000 \t\t Average Reward : 465.61\n",
      "Episode : 887 \t\t Timestep : 888000 \t\t Average Reward : 575.94\n",
      "Episode : 895 \t\t Timestep : 896000 \t\t Average Reward : 562.02\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:34:46\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 903 \t\t Timestep : 904000 \t\t Average Reward : 590.1\n",
      "Episode : 911 \t\t Timestep : 912000 \t\t Average Reward : 471.5\n",
      "Episode : 919 \t\t Timestep : 920000 \t\t Average Reward : 437.5\n",
      "Episode : 927 \t\t Timestep : 928000 \t\t Average Reward : 578.63\n",
      "Episode : 935 \t\t Timestep : 936000 \t\t Average Reward : 575.31\n",
      "Episode : 943 \t\t Timestep : 944000 \t\t Average Reward : 555.46\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:37:54\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 951 \t\t Timestep : 952000 \t\t Average Reward : 514.58\n",
      "Episode : 959 \t\t Timestep : 960000 \t\t Average Reward : 545.41\n",
      "Episode : 967 \t\t Timestep : 968000 \t\t Average Reward : 600.77\n",
      "Episode : 975 \t\t Timestep : 976000 \t\t Average Reward : 479.32\n",
      "Episode : 983 \t\t Timestep : 984000 \t\t Average Reward : 383.23\n",
      "Episode : 991 \t\t Timestep : 992000 \t\t Average Reward : 533.32\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.4\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 999 \t\t Timestep : 1000000 \t\t Average Reward : 406.81\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:40:52\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2024-06-06 02:57:07\n",
      "Finished training at (GMT) :  2024-06-06 03:38:03\n",
      "Total training time  :  0:40:56\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "# printing and logging variables\n",
    "print_running_reward = 0\n",
    "print_running_episodes = 0\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps:\n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "        \n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward = print_running_reward / print_running_episodes\n",
    "            print_avg_reward = round(print_avg_reward, 2)\n",
    "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
    "            print_running_reward = 0\n",
    "            print_running_episodes = 0\n",
    "            \n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path)\n",
    "            ppo_agent.save(checkpoint_path)\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward += current_ep_reward\n",
    "    print_running_episodes += 1\n",
    "    log_running_reward += current_ep_reward\n",
    "    log_running_episodes += 1\n",
    "    i_episode += 1\n",
    "\n",
    "log_f.close()\n",
    "env.close()\n",
    "\n",
    "\n",
    "# print total training time\n",
    "print(\"============================================================================================\")\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"Finished training at (GMT) : \", end_time)\n",
    "print(\"Total training time  : \", end_time - start_time)\n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Model Size: 0.047 MB\n"
     ]
    }
   ],
   "source": [
    "# Compare model sizes and accuracies\n",
    "def get_file_size(path):\n",
    "    return os.path.getsize(path) / 1024**2\n",
    "\n",
    "ppo_model_size = get_file_size(checkpoint_path)\n",
    "print(f\"PPO Model Size: {ppo_model_size:.3f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing environment name : HalfCheetah-v4\n",
      "loading network from : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -301.91\n",
      "Episode: 2 \t\t Reward: 471.22\n",
      "Episode: 3 \t\t Reward: -222.25\n",
      "Episode: 4 \t\t Reward: 363.88\n",
      "Episode: 5 \t\t Reward: 296.16\n",
      "Episode: 6 \t\t Reward: 483.54\n",
      "Episode: 7 \t\t Reward: 396.26\n",
      "Episode: 8 \t\t Reward: 262.35\n",
      "Episode: 9 \t\t Reward: 344.73\n",
      "Episode: 10 \t\t Reward: 59.9\n",
      "============================================================================================\n",
      "average test reward : 215.39\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "total_test_episodes = 10    # total num of testing episodes\n",
    "K_epochs = 80               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "lr_actor = 0.0003           # learning rate for actor\n",
    "lr_critic = 0.001           # learning rate for critic\n",
    "\n",
    "print(\"testing environment name : \" + env_name)\n",
    "env = gym.make(env_name)\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "# preTrained weights directory\n",
    "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
    "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"loading network from : \" + checkpoint_path)\n",
    "ppo_agent.load(checkpoint_path)\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "test_running_reward = 0\n",
    "for ep in range(1, total_test_episodes+1):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    # clear buffer    \n",
    "    ppo_agent.buffer.clear()\n",
    "    test_running_reward +=  ep_reward\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
    "    ep_reward = 0\n",
    "env.close()\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "avg_test_reward = test_running_reward / total_test_episodes\n",
    "avg_test_reward = round(avg_test_reward, 2)\n",
    "print(\"average test reward : \" + str(avg_test_reward))\n",
    "print(\"============================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from : PPO_logs/HalfCheetah-v4//PPO_HalfCheetah-v4_log_0.csv\n",
      "data shape :  (500, 3)\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/IPython/core/pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved at :  PPO_figs/HalfCheetah-v4//PPO_HalfCheetah-v4_fig_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_num = 0     #### change this to prevent overwriting figures in same env_name folder\n",
    "plot_avg = True    # plot average of all runs; else plot all runs separately\n",
    "fig_width = 10\n",
    "fig_height = 6\n",
    "\n",
    "# smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "window_len_smooth = 50\n",
    "min_window_len_smooth = 1\n",
    "linewidth_smooth = 1.5\n",
    "alpha_smooth = 1\n",
    "window_len_var = 5\n",
    "min_window_len_var = 1\n",
    "linewidth_var = 2\n",
    "alpha_var = 0.1\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'olive', 'brown', 'magenta', 'cyan', 'crimson','gray', 'black']\n",
    "\n",
    "# make directory for saving figures\n",
    "figures_dir = \"PPO_figs\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "# make environment directory for saving figures\n",
    "figures_dir = figures_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "fig_save_path = figures_dir + '/PPO_' + env_name + '_fig_' + str(fig_num) + '.png'\n",
    "\n",
    "# get number of log files in directory\n",
    "log_dir = \"PPO_logs\" + '/' + env_name + '/'\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "num_runs = len(current_num_files)\n",
    "\n",
    "all_runs = []\n",
    "for run_num in range(num_runs):\n",
    "    log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "    print(\"loading data from : \" + log_f_name)\n",
    "    data = pd.read_csv(log_f_name)\n",
    "    data = pd.DataFrame(data)\n",
    "    print(\"data shape : \", data.shape)\n",
    "    all_runs.append(data)\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "ax = plt.gca()\n",
    "if plot_avg:\n",
    "    # average all runs\n",
    "    df_concat = pd.concat(all_runs)\n",
    "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
    "    data_avg = df_concat_groupby.mean()\n",
    "    # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "    data_avg['reward_smooth'] = data_avg['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "    data_avg['reward_var'] = data_avg['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_smooth',ax=ax,color=colors[0],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_var',ax=ax,color=colors[0],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "    # keep only reward_smooth in the legend and rename it\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend([handles[0]], [\"reward_avg_\" + str(len(all_runs)) + \"_runs\"], loc=2)\n",
    "else:\n",
    "    for i, run in enumerate(all_runs):\n",
    "        # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "        run['reward_smooth_' + str(i)] = run['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "        run['reward_var_' + str(i)] = run['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "        # plot the lines\n",
    "        run.plot(kind='line', x='timestep' , y='reward_smooth_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "        run.plot(kind='line', x='timestep' , y='reward_var_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "\n",
    "    # keep alternate elements (reward_smooth_i) in the legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = []\n",
    "    new_labels = []\n",
    "    for i in range(len(handles)):\n",
    "        if(i%2 == 0):\n",
    "            new_handles.append(handles[i])\n",
    "            new_labels.append(labels[i])\n",
    "    ax.legend(new_handles, new_labels, loc=2)\n",
    "\n",
    "ax.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
    "ax.set_xlabel(\"Timesteps\", fontsize=12)\n",
    "ax.set_ylabel(\"Rewards\", fontsize=12)\n",
    "plt.title(env_name, fontsize=14)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(fig_width, fig_height)\n",
    "\n",
    "plt.savefig(fig_save_path)\n",
    "print(\"figure saved at : \", fig_save_path)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gif Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_test_episodes = 1     # save gif for only one episode\n",
    "K_epochs = 80               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "lr_actor = 0.0003         # learning rate for actor\n",
    "lr_critic = 0.001         # learning rate for critic\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "# make directory for saving gif images\n",
    "gif_images_dir = \"PPO_gif_images\" + '/'\n",
    "if not os.path.exists(gif_images_dir):\n",
    "    os.makedirs(gif_images_dir)\n",
    "# make environment directory for saving gif images\n",
    "gif_images_dir = gif_images_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(gif_images_dir):\n",
    "    os.makedirs(gif_images_dir)\n",
    "# make directory for gif\n",
    "gif_dir = \"PPO_gifs\" + '/'\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "# make environment directory for gif\n",
    "gif_dir = gif_dir + '/' + env_name  + '/'\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading network from : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/seungan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "MESA: error: ZINK: failed to choose pdev\n",
      "glx: failed to create drisw screen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     21\u001b[0m ep_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m---> 22\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m     24\u001b[0m img\u001b[38;5;241m.\u001b[39msave(gif_images_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(t)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m6\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:58\u001b[0m, in \u001b[0;36m_deprecate_mode.<locals>.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     deprecation(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified the argument render_mode at environment initialization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee here for more information: https://www.gymlibrary.ml/content/api/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:421\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:58\u001b[0m, in \u001b[0;36m_deprecate_mode.<locals>.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     deprecation(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified the argument render_mode at environment initialization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee here for more information: https://www.gymlibrary.ml/content/api/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:58\u001b[0m, in \u001b[0;36m_deprecate_mode.<locals>.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     deprecation(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified the argument render_mode at environment initialization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee here for more information: https://www.gymlibrary.ml/content/api/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:421\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:58\u001b[0m, in \u001b[0;36m_deprecate_mode.<locals>.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     deprecation(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified the argument render_mode at environment initialization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee here for more information: https://www.gymlibrary.ml/content/api/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/wrappers/env_checker.py:55\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/core.py:58\u001b[0m, in \u001b[0;36m_deprecate_mode.<locals>.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     deprecation(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified the argument render_mode at environment initialization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee here for more information: https://www.gymlibrary.ml/content/api/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:198\u001b[0m, in \u001b[0;36mBaseMujocoEnv.render\u001b[0;34m(self, mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    196\u001b[0m width \u001b[38;5;241m=\u001b[39m width \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_SIZE\n\u001b[1;32m    197\u001b[0m height \u001b[38;5;241m=\u001b[39m height \u001b[38;5;28;01mif\u001b[39;00m height \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_SIZE\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:440\u001b[0m, in \u001b[0;36mMujocoEnv._render\u001b[0;34m(self, mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_viewer(mode)\u001b[38;5;241m.\u001b[39mrender(width, height, camera_id\u001b[38;5;241m=\u001b[39mcamera_id)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_rgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 440\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_viewer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# original image is upside-down, so flip it\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_rendering.py:135\u001b[0m, in \u001b[0;36mRenderContext.read_pixels\u001b[0;34m(self, width, height, depth, segmentation)\u001b[0m\n\u001b[1;32m    132\u001b[0m rgb_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m rect\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m*\u001b[39m rect\u001b[38;5;241m.\u001b[39mheight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    133\u001b[0m depth_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(rect\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m*\u001b[39m rect\u001b[38;5;241m.\u001b[39mheight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjr_readPixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m rgb_img \u001b[38;5;241m=\u001b[39m rgb_arr\u001b[38;5;241m.\u001b[39mreshape(rect\u001b[38;5;241m.\u001b[39mheight, rect\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    138\u001b[0m ret_img \u001b[38;5;241m=\u001b[39m rgb_img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "# preTrained weights directory\n",
    "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
    "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
    "\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"loading network from : \" + checkpoint_path)\n",
    "ppo_agent.load(checkpoint_path)\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "test_running_reward = 0\n",
    "for ep in range(1, total_test_episodes+1):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(gif_images_dir + '/' + str(t).zfill(6) + '.jpg')\n",
    "        if done:\n",
    "            break\n",
    "    # clear buffer    \n",
    "    ppo_agent.buffer.clear()\n",
    "\n",
    "    test_running_reward +=  ep_reward\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
    "    ep_reward = 0\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "print(\"total number of frames / timesteps / images saved : \", t)\n",
    "avg_test_reward = test_running_reward / total_test_episodes\n",
    "avg_test_reward = round(avg_test_reward, 2)\n",
    "print(\"average test reward : \" + str(avg_test_reward))\n",
    "print(\"============================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total frames in gif :  30\n",
      "total duration of gif : 4.5 seconds\n",
      "saved gif at :  PPO_gifs/CartPole-v1/PPO_CartPole-v1_gif_0.gif\n"
     ]
    }
   ],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "\n",
    "gif_num = 0     #### change this to prevent overwriting gifs in same env_name folder\n",
    "# adjust following parameters to get desired duration, size (bytes) and smoothness of gif\n",
    "total_timesteps = 300\n",
    "step = 10\n",
    "frame_duration = 150\n",
    "# input images\n",
    "gif_images_dir = \"PPO_gif_images/\" + env_name + '/*.jpg'\n",
    "# ouput gif path\n",
    "gif_dir = \"PPO_gifs\"\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "gif_dir = gif_dir + '/' + env_name\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "gif_path = gif_dir + '/PPO_' + env_name + '_gif_' + str(gif_num) + '.gif'\n",
    "\n",
    "img_paths = sorted(glob.glob(gif_images_dir))\n",
    "img_paths = img_paths[:total_timesteps]\n",
    "img_paths = img_paths[::step]\n",
    "\n",
    "print(\"total frames in gif : \", len(img_paths))\n",
    "print(\"total duration of gif : \" + str(round(len(img_paths) * frame_duration / 1000, 2)) + \" seconds\")\n",
    "\n",
    "# save gif\n",
    "img, *imgs = [Image.open(f) for f in img_paths]\n",
    "img.save(fp=gif_path, format='GIF', append_images=imgs, save_all=True, optimize=True, duration=frame_duration, loop=0)\n",
    "print(\"saved gif at : \", gif_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
